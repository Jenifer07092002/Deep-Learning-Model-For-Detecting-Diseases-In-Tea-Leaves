{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "D7g0AKIcRMvf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Z78497kllJlK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "Z4VWcWVJmIKz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "KCWd7M5PmPmx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle"
      ],
      "metadata": {
        "id": "WERRoyebmmB0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d mohamedafsal007/house-price-dataset-of-india"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYJosH8om7Tx",
        "outputId": "376e9248-7727-4c5f-e2e5-08689f294742"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading house-price-dataset-of-india.zip to /content\n",
            "  0% 0.00/480k [00:00<?, ?B/s]\n",
            "100% 480k/480k [00:00<00:00, 125MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/house-price-dataset-of-india.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zToqKswSnhgb",
        "outputId": "d83b41e7-cfd8-4238-84fd-3cc957c6ffd4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/house-price-dataset-of-india.zip\n",
            "  inflating: House Price India.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "aPNdk1tHoSk7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/house-price-dataset-of-india.zip\")"
      ],
      "metadata": {
        "id": "_pXEMG9upO4X"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwDgdT8frjac",
        "outputId": "882bdd7c-c0c1-4b9b-e41b-6d175d50ecf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'number of bedrooms', 'number of bathrooms', 'living area',\n",
            "       'lot area', 'number of floors', 'waterfront present', 'number of views',\n",
            "       'condition of the house', 'grade of the house',\n",
            "       'Area of the house(excluding basement)', 'Area of the basement',\n",
            "       'Built Year', 'Renovation Year', 'Postal Code', 'Lattitude',\n",
            "       'Longitude', 'living_area_renov', 'lot_area_renov',\n",
            "       'Number of schools nearby', 'Distance from the airport', 'Price'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Postal Code', 'Lattitude', 'Longitude'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "zmSTAs0Sqriz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['number of bedrooms'] = df['number of bedrooms'].astype(int)"
      ],
      "metadata": {
        "id": "aNvqbIBQpanf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns=['waterfront present', 'Distance from the airport'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "FO6phOLnpwoJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L8BJsKz7RL92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('Price',axis=1), df['Price'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "nDu0yH--sfL5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train[X_train.select_dtypes(include=['float64', 'int64']).columns] = scaler.fit_transform(X_train.select_dtypes(include=['float64', 'int64']))\n",
        "X_test[X_test.select_dtypes(include=['float64', 'int64']).columns] = scaler.transform(X_test.select_dtypes(include=['float64', 'int64']))"
      ],
      "metadata": {
        "id": "msRfnrPPslTn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build the ANN model"
      ],
      "metadata": {
        "id": "QI7gQ2jOsueR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "KTK4CItRs0J2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(16, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "CMA921vps4eo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "metadata": {
        "id": "vzhEQ_IJs-Lt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "iwQ6c2g6tHgl",
        "outputId": "79b9114c-4d4a-4a1d-c399-2e8093273f14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "293/293 [==============================] - 2s 3ms/step - loss: 423739621376.0000 - val_loss: 404482523136.0000\n",
            "Epoch 2/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 365127729152.0000 - val_loss: 265305800704.0000\n",
            "Epoch 3/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 160291520512.0000 - val_loss: 80253460480.0000\n",
            "Epoch 4/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 67427028992.0000 - val_loss: 58624151552.0000\n",
            "Epoch 5/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 55766499328.0000 - val_loss: 50850062336.0000\n",
            "Epoch 6/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 49711562752.0000 - val_loss: 45627662336.0000\n",
            "Epoch 7/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 45094449152.0000 - val_loss: 41051017216.0000\n",
            "Epoch 8/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 41406697472.0000 - val_loss: 37509951488.0000\n",
            "Epoch 9/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 38508621824.0000 - val_loss: 34581553152.0000\n",
            "Epoch 10/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 36359962624.0000 - val_loss: 32735184896.0000\n",
            "Epoch 11/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 34643316736.0000 - val_loss: 31064965120.0000\n",
            "Epoch 12/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 33387743232.0000 - val_loss: 29901928448.0000\n",
            "Epoch 13/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 32417005568.0000 - val_loss: 29156898816.0000\n",
            "Epoch 14/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 31649263616.0000 - val_loss: 28644456448.0000\n",
            "Epoch 15/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 31030304768.0000 - val_loss: 27881334784.0000\n",
            "Epoch 16/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 30552557568.0000 - val_loss: 27472439296.0000\n",
            "Epoch 17/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 30051887104.0000 - val_loss: 27093868544.0000\n",
            "Epoch 18/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 29629368320.0000 - val_loss: 26831714304.0000\n",
            "Epoch 19/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 29209860096.0000 - val_loss: 26917816320.0000\n",
            "Epoch 20/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 28812470272.0000 - val_loss: 26142148608.0000\n",
            "Epoch 21/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 28483500032.0000 - val_loss: 26522552320.0000\n",
            "Epoch 22/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 28219357184.0000 - val_loss: 25674414080.0000\n",
            "Epoch 23/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 27932618752.0000 - val_loss: 25480957952.0000\n",
            "Epoch 24/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 27647797248.0000 - val_loss: 25524447232.0000\n",
            "Epoch 25/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 27391635456.0000 - val_loss: 25065857024.0000\n",
            "Epoch 26/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 27170537472.0000 - val_loss: 25150681088.0000\n",
            "Epoch 27/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 26899906560.0000 - val_loss: 24982433792.0000\n",
            "Epoch 28/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 26697930752.0000 - val_loss: 24728952832.0000\n",
            "Epoch 29/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 26521794560.0000 - val_loss: 24396871680.0000\n",
            "Epoch 30/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 26292328448.0000 - val_loss: 24340998144.0000\n",
            "Epoch 31/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 26111076352.0000 - val_loss: 24375392256.0000\n",
            "Epoch 32/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 25891850240.0000 - val_loss: 24074510336.0000\n",
            "Epoch 33/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 25769594880.0000 - val_loss: 23966050304.0000\n",
            "Epoch 34/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 25494280192.0000 - val_loss: 23747074048.0000\n",
            "Epoch 35/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 25392881664.0000 - val_loss: 23703506944.0000\n",
            "Epoch 36/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 25248741376.0000 - val_loss: 23614021632.0000\n",
            "Epoch 37/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 25014382592.0000 - val_loss: 23401412608.0000\n",
            "Epoch 38/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 24960681984.0000 - val_loss: 23414515712.0000\n",
            "Epoch 39/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 24811335680.0000 - val_loss: 23337648128.0000\n",
            "Epoch 40/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 24614172672.0000 - val_loss: 23162443776.0000\n",
            "Epoch 41/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 24468555776.0000 - val_loss: 23030411264.0000\n",
            "Epoch 42/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 24358197248.0000 - val_loss: 22929238016.0000\n",
            "Epoch 43/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 24254932992.0000 - val_loss: 22986573824.0000\n",
            "Epoch 44/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 24102379520.0000 - val_loss: 22846050304.0000\n",
            "Epoch 45/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 24005234688.0000 - val_loss: 22846496768.0000\n",
            "Epoch 46/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 23862306816.0000 - val_loss: 22701568000.0000\n",
            "Epoch 47/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 23757473792.0000 - val_loss: 22747023360.0000\n",
            "Epoch 48/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 23620642816.0000 - val_loss: 22762045440.0000\n",
            "Epoch 49/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 23538563072.0000 - val_loss: 22720348160.0000\n",
            "Epoch 50/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 23376037888.0000 - val_loss: 22500106240.0000\n",
            "Epoch 51/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 23351810048.0000 - val_loss: 22408017920.0000\n",
            "Epoch 52/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 23163969536.0000 - val_loss: 22227462144.0000\n",
            "Epoch 53/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 23072344064.0000 - val_loss: 22584821760.0000\n",
            "Epoch 54/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 22997078016.0000 - val_loss: 22267441152.0000\n",
            "Epoch 55/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 22886166528.0000 - val_loss: 22206519296.0000\n",
            "Epoch 56/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 22749886464.0000 - val_loss: 21941854208.0000\n",
            "Epoch 57/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 22648496128.0000 - val_loss: 22117904384.0000\n",
            "Epoch 58/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 22588766208.0000 - val_loss: 22096410624.0000\n",
            "Epoch 59/100\n",
            "293/293 [==============================] - 1s 5ms/step - loss: 22506436608.0000 - val_loss: 21988478976.0000\n",
            "Epoch 60/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 22377312256.0000 - val_loss: 21756936192.0000\n",
            "Epoch 61/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 22304167936.0000 - val_loss: 21881792512.0000\n",
            "Epoch 62/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 22217109504.0000 - val_loss: 21878945792.0000\n",
            "Epoch 63/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 22108798976.0000 - val_loss: 21997373440.0000\n",
            "Epoch 64/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 21993297920.0000 - val_loss: 21601198080.0000\n",
            "Epoch 65/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 21958072320.0000 - val_loss: 21593044992.0000\n",
            "Epoch 66/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 21869504512.0000 - val_loss: 21429850112.0000\n",
            "Epoch 67/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 21784559616.0000 - val_loss: 21507436544.0000\n",
            "Epoch 68/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 21671581696.0000 - val_loss: 21329879040.0000\n",
            "Epoch 69/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 21661544448.0000 - val_loss: 21251936256.0000\n",
            "Epoch 70/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 21506099200.0000 - val_loss: 21197393920.0000\n",
            "Epoch 71/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 21463111680.0000 - val_loss: 21091528704.0000\n",
            "Epoch 72/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 21359847424.0000 - val_loss: 21087453184.0000\n",
            "Epoch 73/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 21291927552.0000 - val_loss: 21163597824.0000\n",
            "Epoch 74/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 21192351744.0000 - val_loss: 21231652864.0000\n",
            "Epoch 75/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 21125890048.0000 - val_loss: 21080657920.0000\n",
            "Epoch 76/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 21007007744.0000 - val_loss: 21270523904.0000\n",
            "Epoch 77/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 20983834624.0000 - val_loss: 20983255040.0000\n",
            "Epoch 78/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 20870381568.0000 - val_loss: 20761210880.0000\n",
            "Epoch 79/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 20779591680.0000 - val_loss: 21045463040.0000\n",
            "Epoch 80/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 20702885888.0000 - val_loss: 20730353664.0000\n",
            "Epoch 81/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 20647153664.0000 - val_loss: 20598079488.0000\n",
            "Epoch 82/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 20607905792.0000 - val_loss: 20633702400.0000\n",
            "Epoch 83/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 20501577728.0000 - val_loss: 20688828416.0000\n",
            "Epoch 84/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 20415350784.0000 - val_loss: 20652062720.0000\n",
            "Epoch 85/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 20349990912.0000 - val_loss: 20842160128.0000\n",
            "Epoch 86/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 20278861824.0000 - val_loss: 20406472704.0000\n",
            "Epoch 87/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 20213596160.0000 - val_loss: 20427028480.0000\n",
            "Epoch 88/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 20130088960.0000 - val_loss: 20739856384.0000\n",
            "Epoch 89/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 20037666816.0000 - val_loss: 20312803328.0000\n",
            "Epoch 90/100\n",
            "293/293 [==============================] - 1s 4ms/step - loss: 19982753792.0000 - val_loss: 20227082240.0000\n",
            "Epoch 91/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 19937669120.0000 - val_loss: 20194838528.0000\n",
            "Epoch 92/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 19855450112.0000 - val_loss: 20140855296.0000\n",
            "Epoch 93/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 19816935424.0000 - val_loss: 20117612544.0000\n",
            "Epoch 94/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 19730454528.0000 - val_loss: 20080879616.0000\n",
            "Epoch 95/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 19651805184.0000 - val_loss: 20053295104.0000\n",
            "Epoch 96/100\n",
            "293/293 [==============================] - 1s 2ms/step - loss: 19611664384.0000 - val_loss: 19985088512.0000\n",
            "Epoch 97/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 19525304320.0000 - val_loss: 20034217984.0000\n",
            "Epoch 98/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 19416174592.0000 - val_loss: 19831099392.0000\n",
            "Epoch 99/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 19480690688.0000 - val_loss: 19859566592.0000\n",
            "Epoch 100/100\n",
            "293/293 [==============================] - 1s 3ms/step - loss: 19394301952.0000 - val_loss: 19843129344.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45e37f3eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test the model"
      ],
      "metadata": {
        "id": "FbY_21SKtizg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "tooIMprFte5o",
        "outputId": "204fbf7e-de66-4071-bfe1-38158369689b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Mean Absolute Error:\",mae)"
      ],
      "metadata": {
        "id": "hzVHRBJRtoW0",
        "outputId": "07cb774c-5640-4135-8dff-9e8aab57b29a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 20136111864.436527\n",
            "Mean Absolute Error: 70369.5379510089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "metadata": {
        "id": "xCNXjZqBPxKi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))"
      ],
      "metadata": {
        "id": "owNuxsJkuNWS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwvkM16ETze4",
        "outputId": "fee452d7-2666-470a-9dea-b07652ee241f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "366/366 [==============================] - 5s 5ms/step - loss: 422476840960.0000\n",
            "Epoch 2/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 416561233920.0000\n",
            "Epoch 3/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 396898795520.0000\n",
            "Epoch 4/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 359910473728.0000\n",
            "Epoch 5/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 307601637376.0000\n",
            "Epoch 6/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 247593172992.0000\n",
            "Epoch 7/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 188157624320.0000\n",
            "Epoch 8/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 138191503360.0000\n",
            "Epoch 9/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 103130890240.0000\n",
            "Epoch 10/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 82120589312.0000\n",
            "Epoch 11/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 70712008704.0000\n",
            "Epoch 12/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 64407384064.0000\n",
            "Epoch 13/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 60487774208.0000\n",
            "Epoch 14/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 57577033728.0000\n",
            "Epoch 15/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 55106187264.0000\n",
            "Epoch 16/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 52926550016.0000\n",
            "Epoch 17/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 50887753728.0000\n",
            "Epoch 18/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 48994398208.0000\n",
            "Epoch 19/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 47221882880.0000\n",
            "Epoch 20/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 45565284352.0000\n",
            "Epoch 21/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 44027768832.0000\n",
            "Epoch 22/100\n",
            "366/366 [==============================] - 2s 5ms/step - loss: 42599866368.0000\n",
            "Epoch 23/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 41270059008.0000\n",
            "Epoch 24/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 40088059904.0000\n",
            "Epoch 25/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 38981038080.0000\n",
            "Epoch 26/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 37984514048.0000\n",
            "Epoch 27/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 37112205312.0000\n",
            "Epoch 28/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 36317908992.0000\n",
            "Epoch 29/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 35616366592.0000\n",
            "Epoch 30/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 34998894592.0000\n",
            "Epoch 31/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 34465968128.0000\n",
            "Epoch 32/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 33999699968.0000\n",
            "Epoch 33/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 33572366336.0000\n",
            "Epoch 34/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 33192986624.0000\n",
            "Epoch 35/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 32861927424.0000\n",
            "Epoch 36/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 32550463488.0000\n",
            "Epoch 37/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 32270903296.0000\n",
            "Epoch 38/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 32012711936.0000\n",
            "Epoch 39/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 31763234816.0000\n",
            "Epoch 40/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 31540631552.0000\n",
            "Epoch 41/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 31319756800.0000\n",
            "Epoch 42/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 31120277504.0000\n",
            "Epoch 43/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 30923966464.0000\n",
            "Epoch 44/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 30738944000.0000\n",
            "Epoch 45/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 30558574592.0000\n",
            "Epoch 46/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 30370516992.0000\n",
            "Epoch 47/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 30192869376.0000\n",
            "Epoch 48/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 30022600704.0000\n",
            "Epoch 49/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 29850634240.0000\n",
            "Epoch 50/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 29675925504.0000\n",
            "Epoch 51/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 29539022848.0000\n",
            "Epoch 52/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 29375518720.0000\n",
            "Epoch 53/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 29213095936.0000\n",
            "Epoch 54/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 29077315584.0000\n",
            "Epoch 55/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 28935170048.0000\n",
            "Epoch 56/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 28791017472.0000\n",
            "Epoch 57/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 28662614016.0000\n",
            "Epoch 58/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 28528652288.0000\n",
            "Epoch 59/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 28389652480.0000\n",
            "Epoch 60/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 28273702912.0000\n",
            "Epoch 61/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 28150730752.0000\n",
            "Epoch 62/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 28042731520.0000\n",
            "Epoch 63/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 27925807104.0000\n",
            "Epoch 64/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 27812438016.0000\n",
            "Epoch 65/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 27708008448.0000\n",
            "Epoch 66/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 27598848000.0000\n",
            "Epoch 67/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 27493310464.0000\n",
            "Epoch 68/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 27398367232.0000\n",
            "Epoch 69/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 27304527872.0000\n",
            "Epoch 70/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 27210188800.0000\n",
            "Epoch 71/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 27121176576.0000\n",
            "Epoch 72/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 27029338112.0000\n",
            "Epoch 73/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 26956720128.0000\n",
            "Epoch 74/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 26859649024.0000\n",
            "Epoch 75/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 26778296320.0000\n",
            "Epoch 76/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 26689875968.0000\n",
            "Epoch 77/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 26617618432.0000\n",
            "Epoch 78/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 26533611520.0000\n",
            "Epoch 79/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 26456723456.0000\n",
            "Epoch 80/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 26385537024.0000\n",
            "Epoch 81/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 26317484032.0000\n",
            "Epoch 82/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 26236682240.0000\n",
            "Epoch 83/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 26166804480.0000\n",
            "Epoch 84/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 26090960896.0000\n",
            "Epoch 85/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 26029500416.0000\n",
            "Epoch 86/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25966055424.0000\n",
            "Epoch 87/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25886629888.0000\n",
            "Epoch 88/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25827006464.0000\n",
            "Epoch 89/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 25762844672.0000\n",
            "Epoch 90/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 25685374976.0000\n",
            "Epoch 91/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 25640388608.0000\n",
            "Epoch 92/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25569099776.0000\n",
            "Epoch 93/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25505869824.0000\n",
            "Epoch 94/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25455544320.0000\n",
            "Epoch 95/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25391208448.0000\n",
            "Epoch 96/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25334620160.0000\n",
            "Epoch 97/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25253412864.0000\n",
            "Epoch 98/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25226643456.0000\n",
            "Epoch 99/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25148731392.0000\n",
            "Epoch 100/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 25110630400.0000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 24294176768.0000\n",
            "Test Loss: 24294176768.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FdZvuaaTqd4",
        "outputId": "f0a06f74-80f3-47cb-f932-8c3a60172e63"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 25045864448.0000\n",
            "Epoch 2/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 24988960768.0000\n",
            "Epoch 3/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24924663808.0000\n",
            "Epoch 4/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24873490432.0000\n",
            "Epoch 5/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24814016512.0000\n",
            "Epoch 6/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24780627968.0000\n",
            "Epoch 7/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24731410432.0000\n",
            "Epoch 8/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24660545536.0000\n",
            "Epoch 9/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24613169152.0000\n",
            "Epoch 10/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24562257920.0000\n",
            "Epoch 11/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24522807296.0000\n",
            "Epoch 12/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24462735360.0000\n",
            "Epoch 13/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24419672064.0000\n",
            "Epoch 14/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24372465664.0000\n",
            "Epoch 15/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24334542848.0000\n",
            "Epoch 16/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24287924224.0000\n",
            "Epoch 17/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 24231243776.0000\n",
            "Epoch 18/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 24183146496.0000\n",
            "Epoch 19/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24134334464.0000\n",
            "Epoch 20/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24091146240.0000\n",
            "Epoch 21/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24049813504.0000\n",
            "Epoch 22/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 24005552128.0000\n",
            "Epoch 23/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23948470272.0000\n",
            "Epoch 24/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23907780608.0000\n",
            "Epoch 25/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23858870272.0000\n",
            "Epoch 26/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23814381568.0000\n",
            "Epoch 27/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23776927744.0000\n",
            "Epoch 28/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23733567488.0000\n",
            "Epoch 29/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23713501184.0000\n",
            "Epoch 30/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23655393280.0000\n",
            "Epoch 31/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23601813504.0000\n",
            "Epoch 32/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23584827392.0000\n",
            "Epoch 33/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 23526723584.0000\n",
            "Epoch 34/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 23485734912.0000\n",
            "Epoch 35/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23440377856.0000\n",
            "Epoch 36/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23400306688.0000\n",
            "Epoch 37/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23349196800.0000\n",
            "Epoch 38/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23330013184.0000\n",
            "Epoch 39/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23302238208.0000\n",
            "Epoch 40/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23240472576.0000\n",
            "Epoch 41/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23206721536.0000\n",
            "Epoch 42/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23170740224.0000\n",
            "Epoch 43/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23131432960.0000\n",
            "Epoch 44/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23100936192.0000\n",
            "Epoch 45/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23065255936.0000\n",
            "Epoch 46/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 23015759872.0000\n",
            "Epoch 47/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22973609984.0000\n",
            "Epoch 48/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22937880576.0000\n",
            "Epoch 49/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 22907568128.0000\n",
            "Epoch 50/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 22861015040.0000\n",
            "Epoch 51/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 22841305088.0000\n",
            "Epoch 52/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22795268096.0000\n",
            "Epoch 53/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22762188800.0000\n",
            "Epoch 54/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22736764928.0000\n",
            "Epoch 55/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22693107712.0000\n",
            "Epoch 56/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22661093376.0000\n",
            "Epoch 57/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22626271232.0000\n",
            "Epoch 58/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22593564672.0000\n",
            "Epoch 59/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22556624896.0000\n",
            "Epoch 60/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22519578624.0000\n",
            "Epoch 61/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22490882048.0000\n",
            "Epoch 62/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22448674816.0000\n",
            "Epoch 63/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22412800000.0000\n",
            "Epoch 64/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22387050496.0000\n",
            "Epoch 65/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 22359396352.0000\n",
            "Epoch 66/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 22324262912.0000\n",
            "Epoch 67/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22293094400.0000\n",
            "Epoch 68/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22257002496.0000\n",
            "Epoch 69/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22231212032.0000\n",
            "Epoch 70/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22208294912.0000\n",
            "Epoch 71/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22170695680.0000\n",
            "Epoch 72/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22128543744.0000\n",
            "Epoch 73/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22092754944.0000\n",
            "Epoch 74/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22078289920.0000\n",
            "Epoch 75/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22043373568.0000\n",
            "Epoch 76/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 22009098240.0000\n",
            "Epoch 77/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21980391424.0000\n",
            "Epoch 78/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21945446400.0000\n",
            "Epoch 79/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21915115520.0000\n",
            "Epoch 80/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 21891149824.0000\n",
            "Epoch 81/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 21852446720.0000\n",
            "Epoch 82/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 21829255168.0000\n",
            "Epoch 83/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21804826624.0000\n",
            "Epoch 84/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21786275840.0000\n",
            "Epoch 85/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21729708032.0000\n",
            "Epoch 86/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21720567808.0000\n",
            "Epoch 87/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21679532032.0000\n",
            "Epoch 88/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21647742976.0000\n",
            "Epoch 89/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21619355648.0000\n",
            "Epoch 90/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21586348032.0000\n",
            "Epoch 91/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21556244480.0000\n",
            "Epoch 92/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21536376832.0000\n",
            "Epoch 93/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21514344448.0000\n",
            "Epoch 94/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21479673856.0000\n",
            "Epoch 95/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21447569408.0000\n",
            "Epoch 96/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21433225216.0000\n",
            "Epoch 97/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 21395548160.0000\n",
            "Epoch 98/100\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 21376579584.0000\n",
            "Epoch 99/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21337044992.0000\n",
            "Epoch 100/100\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 21313400832.0000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 21733144576.0000\n",
            "Test Loss: 21733144576.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOZ_i45acjQZ",
        "outputId": "ec45947f-2f04-4c0e-dda8-2951d4533c0b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Create a DataFrame with actual and predicted values\n",
        "results = pd.DataFrame({'Actual value': y_test.values.flatten(), 'Predicted value': y_pred.flatten().astype('int')})\n",
        "\n",
        "# Display the first 10 rows\n",
        "print(results.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5aNKDbvcwR6",
        "outputId": "49c144de-2cc2-4810-d152-2f3ca6834249"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 1s 5ms/step\n",
            "   Actual value  Predicted value\n",
            "0        235000           260047\n",
            "1        552000           599529\n",
            "2        615000           630833\n",
            "3        555000           604216\n",
            "4        649950           688640\n",
            "5        257700           225649\n",
            "6        980000           925260\n",
            "7        535000           574576\n",
            "8       1030000           941478\n",
            "9        549950           525593\n"
          ]
        }
      ]
    }
  ]
}